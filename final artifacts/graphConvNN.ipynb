{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse, time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import os, sys\n",
    "from dgl.data import register_data_args, load_data\n",
    "import pandas as pd\n",
    "from gcn import GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def _encode_onehot(labels):\n",
    "    classes = list(sorted(set(labels)))\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot\n",
    "\n",
    "def _sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return mask\n",
    "\n",
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>CernDataset class is built based on the strucurue of coreDataset </b><br>\n",
    "find it here: https://github.com/dmlc/dgl/blob/master/python/dgl/data/citation_graph.py <br>\n",
    "The code will build a fully connected graph between layer. each node (layercluster) is fully connected to all nodes from previous layer. In other word, each node is a parent for each and every node in the next layer. \n",
    "<br><br>\n",
    "<b>train_size</b> defines the propotion of nodes selected for training. <br>\n",
    "<b>val_size</b> defines the propotion of nodes selected for Validation.<br>\n",
    "all left (1 - train_size - val_size) is allocated for Test.(<b>test_size</b><br>\n",
    "actual validation may be less than <b>val_size</b> as after creating the mask we remove the nodes allocated for train from it using these two mask commands: <br>\n",
    "xor_val_train=np.bitwise_xor(val_mask,train_mask) <br>\n",
    "_val_mask=np.bitwise_and(val_mask,xor_val_train)<br><br>\n",
    "That means, test_size may be greater than actual \"1 - train_size - val_size\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CernDataset(object):\n",
    "    def getListEventLayerTrackster(self, df, event, trackster,layer):\n",
    "        filtered_df = df.loc[(df['event'] == event) & (df['layer'] ==layer) & (df['trackster'] ==trackster)]\n",
    "        return filtered_df\n",
    "\n",
    "    def __init__(self):\n",
    "         self.store_oct27 = pd.read_hdf(\"singlepi_e100GeV_pu200_oct27.h5\")\n",
    "         #filter out some events - to minimize the processing time during development.\n",
    "         #self.store_oct27 = self.store_oct27[self.store_oct27['event'] < 5 ]\n",
    "         self.store_oct27['purity']=self.store_oct27['purity'].apply(lambda x: 0 if x <=1 else 1 )\n",
    "         self.df = self.store_oct27.drop(['eta','phi','layer','trckPhi','trckEn','trckEta','trckType'],1,inplace=False)\n",
    "         self._load()\n",
    "         \n",
    "    def _load(self):\n",
    "        \n",
    "        idx_features_labels =  self.df.drop(['purity','event','trackster'],1,inplace=False)\n",
    "        idx_features_labels = idx_features_labels.to_numpy()\n",
    "        features = sp.csr_matrix(idx_features_labels,dtype=np.float32)\n",
    "        labels = _encode_onehot(self.df[['purity']].iloc[:,0])\n",
    "        self.num_labels = labels.shape[1]\n",
    "        \n",
    "        # build graph\n",
    "        edges_flatted =[]\n",
    "        for idx, row in self.store_oct27.iterrows():\n",
    "            prev_layer = self.getListEventLayerTrackster(self.store_oct27, row['event'],row['trackster'],row['layer']-1)\n",
    "            for jdx,row in prev_layer.iterrows():\n",
    "                edges_flatted.append(jdx)\n",
    "                edges_flatted.append(idx)\n",
    "                \n",
    "        edges= np.array(edges_flatted).reshape(len(edges_flatted) // 2,2)\n",
    "        \n",
    "        adj = sp.coo_matrix((np.ones(edges.shape[0]),\n",
    "                             (edges[:, 0], edges[:, 1])),\n",
    "                            shape=(labels.shape[0], labels.shape[0]),\n",
    "                            dtype=np.float32)\n",
    "\n",
    "        self.graph = nx.from_scipy_sparse_matrix(adj, create_using=nx.DiGraph())\n",
    "\n",
    "        features = _normalize(features)\n",
    "        self.features = np.array(features.todense())\n",
    "        self.labels = np.where(labels)[1]\n",
    "        #test_size = int(labels.shape[0] * 0.15)\n",
    "        train_size = int(labels.shape[0] * 0.15)\n",
    "        val_size = int(labels.shape[0] * 0.50)\n",
    "        \n",
    "        train_mask= np.zeros(labels.shape[0], dtype=int)\n",
    "        train_mask[:train_size] = 1\n",
    "        np.random.shuffle(train_mask)\n",
    "        self.train_mask = train_mask\n",
    "        \n",
    "        val_mask= np.zeros(labels.shape[0], dtype=int)\n",
    "        val_mask[:val_size] = 1\n",
    "        np.random.shuffle(val_mask)\n",
    "        xor_val_train=np.bitwise_xor(val_mask,train_mask)\n",
    "        _val_mask=np.bitwise_and(val_mask,xor_val_train)\n",
    "        \n",
    "        self.val_mask = _val_mask.tolist()\n",
    "        #all layercluster not chosen for training or validation will be added to the test \n",
    "        test_mask = np.bitwise_or(self.val_mask,self.train_mask)\n",
    "        _test_mask = np.invert(test_mask)\n",
    "        self.test_mask = _test_mask.tolist()\n",
    "        #self.train_mask = _sample_mask(range(1500), labels.shape[0])\n",
    "        #self.val_mask = _sample_mask(range(2000, 5000), labels.shape[0])\n",
    "        #self.test_mask = _sample_mask(range(5000, 8000), labels.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx == 0, \"This dataset has only one graph\"\n",
    "        g = DGLGraph(self.graph)\n",
    "        g.ndata['train_mask'] = self.train_mask\n",
    "        g.ndata['val_mask'] = self.val_mask\n",
    "        g.ndata['test_mask'] = self.test_mask\n",
    "        g.ndata['label'] = self.labels\n",
    "        g.ndata['feat'] = self.features\n",
    "        return g\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup the model - configurable parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dummy(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args= dummy()\n",
    "args.dropout=0.3 #dropout probability\n",
    "args.gpu=-1\n",
    "args.lr=0.01 #learning rate\n",
    "args.n_epochs=15\n",
    "args.n_hidden=16 #number of hidden gcn units\n",
    "args.n_layers=3\n",
    "args.self_loop=False #graph self-loop \n",
    "args.weight_decay=0.0005\n",
    "args.dataset = CernDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphCovNN(args):\n",
    "    # load and preprocess dataset\n",
    "    data = args.dataset\n",
    "    features = torch.FloatTensor(data.features)\n",
    "    labels = torch.LongTensor(data.labels)\n",
    "    if hasattr(torch, 'BoolTensor'):\n",
    "        train_mask = torch.BoolTensor(data.train_mask)\n",
    "        val_mask = torch.BoolTensor(data.val_mask)\n",
    "        test_mask = torch.BoolTensor(data.test_mask)\n",
    "    else:\n",
    "        train_mask = torch.ByteTensor(data.train_mask)\n",
    "        val_mask = torch.ByteTensor(data.val_mask)\n",
    "        test_mask = torch.ByteTensor(data.test_mask)\n",
    "    in_feats = features.shape[1]\n",
    "    n_classes = data.num_labels\n",
    "    n_edges = data.graph.number_of_edges()\n",
    "    print(\"\"\"----Data statistics------'\n",
    "      #Edges %d\n",
    "      #Classes %d\n",
    "      #Train samples %d\n",
    "      #Val samples %d\n",
    "      #Test samples %d\"\"\" %\n",
    "          (n_edges, n_classes,\n",
    "              train_mask.int().sum().item(),\n",
    "              val_mask.int().sum().item(),\n",
    "              test_mask.int().sum().item()))\n",
    "\n",
    "    if args.gpu < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        train_mask = train_mask.cuda()\n",
    "        val_mask = val_mask.cuda()\n",
    "        test_mask = test_mask.cuda()\n",
    "\n",
    "    # graph preprocess and calculate normalization factor\n",
    "    g = data.graph\n",
    "    # add self loop\n",
    "    if args.self_loop:\n",
    "        g.remove_edges_from(nx.selfloop_edges(g))\n",
    "        g.add_edges_from(zip(g.nodes(), g.nodes()))\n",
    "    g = DGLGraph(g)\n",
    "    n_edges = g.number_of_edges()\n",
    "    # normalization\n",
    "    degs = g.in_degrees().float()\n",
    "    norm = torch.pow(degs, -0.5)\n",
    "    norm[torch.isinf(norm)] = 0\n",
    "    if cuda:\n",
    "        norm = norm.cuda()\n",
    "    g.ndata['norm'] = norm.unsqueeze(1)\n",
    "\n",
    "    # create GCN model\n",
    "    model = GCN(g,\n",
    "                in_feats,\n",
    "                args.n_hidden,\n",
    "                n_classes,\n",
    "                args.n_layers,\n",
    "                F.relu,\n",
    "                args.dropout)\n",
    "\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # use optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=args.lr,\n",
    "                                 weight_decay=args.weight_decay)\n",
    "\n",
    "    # initialize graph\n",
    "    dur = []\n",
    "    for epoch in range(args.n_epochs):\n",
    "        model.train()\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        # forward\n",
    "        logits = model(features)\n",
    "        loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        acc = evaluate(model, features, labels, val_mask)\n",
    "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} |\"\n",
    "              \"ETputs(KTEPS) {:.2f}\". format(epoch, np.mean(dur), loss.item(),\n",
    "                                             n_edges / np.mean(dur) / 1000))\n",
    "\n",
    "    print()\n",
    "    acc = evaluate(model, features, labels, test_mask)\n",
    "    print(\"Test accuracy {:.2%}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Data statistics------'\n",
      "      #Edges 514910\n",
      "      #Classes 2\n",
      "      #Train samples 4841\n",
      "      #Val samples 13738\n",
      "      #Test samples 32274\n",
      "Epoch 00000 | Time(s) nan | Loss 0.6726 |ETputs(KTEPS) nan\n",
      "Epoch 00001 | Time(s) nan | Loss 0.6295 |ETputs(KTEPS) nan\n",
      "Epoch 00002 | Time(s) nan | Loss 0.5932 |ETputs(KTEPS) nan\n",
      "Epoch 00003 | Time(s) 0.1812 | Loss 0.5644 |ETputs(KTEPS) 2841.89\n",
      "Epoch 00004 | Time(s) 0.2086 | Loss 0.5430 |ETputs(KTEPS) 2468.45\n",
      "Epoch 00005 | Time(s) 0.2054 | Loss 0.5251 |ETputs(KTEPS) 2506.71\n",
      "Epoch 00006 | Time(s) 0.1938 | Loss 0.5131 |ETputs(KTEPS) 2656.38\n",
      "Epoch 00007 | Time(s) 0.1931 | Loss 0.5076 |ETputs(KTEPS) 2666.84\n",
      "Epoch 00008 | Time(s) 0.1941 | Loss 0.5069 |ETputs(KTEPS) 2653.34\n",
      "Epoch 00009 | Time(s) 0.1946 | Loss 0.5075 |ETputs(KTEPS) 2646.61\n",
      "Epoch 00010 | Time(s) 0.1942 | Loss 0.5104 |ETputs(KTEPS) 2650.81\n",
      "Epoch 00011 | Time(s) 0.1950 | Loss 0.5092 |ETputs(KTEPS) 2640.96\n",
      "Epoch 00012 | Time(s) 0.1931 | Loss 0.5071 |ETputs(KTEPS) 2666.91\n",
      "Epoch 00013 | Time(s) 0.1911 | Loss 0.4995 |ETputs(KTEPS) 2694.22\n",
      "Epoch 00014 | Time(s) 0.1920 | Loss 0.5017 |ETputs(KTEPS) 2681.14\n",
      "\n",
      "Test accuracy 80.45%\n"
     ]
    }
   ],
   "source": [
    "graphCovNN(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "args1= dummy()\n",
    "args1.dropout=0.5 #dropout probability\n",
    "args1.gpu=-1\n",
    "args1.lr=0.01 #learning rate\n",
    "args1.n_epochs=15\n",
    "args1.n_hidden=32 #number of hidden gcn units\n",
    "args1.n_layers=3\n",
    "args1.self_loop=False #graph self-loop \n",
    "args1.weight_decay=0.0005\n",
    "args1.dataset = CernDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Data statistics------'\n",
      "      #Edges 514910\n",
      "      #Classes 2\n",
      "      #Train samples 4841\n",
      "      #Val samples 13676\n",
      "      #Test samples 32274\n",
      "Epoch 00000 | Time(s) nan | Loss 0.6944 |ETputs(KTEPS) nan\n",
      "Epoch 00001 | Time(s) nan | Loss 0.6532 |ETputs(KTEPS) nan\n",
      "Epoch 00002 | Time(s) nan | Loss 0.6093 |ETputs(KTEPS) nan\n",
      "Epoch 00003 | Time(s) 0.2835 | Loss 0.5693 |ETputs(KTEPS) 1815.98\n",
      "Epoch 00004 | Time(s) 0.2958 | Loss 0.5358 |ETputs(KTEPS) 1740.86\n",
      "Epoch 00005 | Time(s) 0.3093 | Loss 0.5093 |ETputs(KTEPS) 1664.81\n",
      "Epoch 00006 | Time(s) 0.3126 | Loss 0.5003 |ETputs(KTEPS) 1647.01\n",
      "Epoch 00007 | Time(s) 0.3079 | Loss 0.5044 |ETputs(KTEPS) 1672.59\n",
      "Epoch 00008 | Time(s) 0.3035 | Loss 0.5168 |ETputs(KTEPS) 1696.65\n",
      "Epoch 00009 | Time(s) 0.3021 | Loss 0.5239 |ETputs(KTEPS) 1704.64\n",
      "Epoch 00010 | Time(s) 0.3013 | Loss 0.5177 |ETputs(KTEPS) 1708.72\n",
      "Epoch 00011 | Time(s) 0.3006 | Loss 0.5078 |ETputs(KTEPS) 1712.68\n",
      "Epoch 00012 | Time(s) 0.3060 | Loss 0.4915 |ETputs(KTEPS) 1682.56\n",
      "Epoch 00013 | Time(s) 0.3082 | Loss 0.4932 |ETputs(KTEPS) 1670.49\n",
      "Epoch 00014 | Time(s) 0.3084 | Loss 0.4879 |ETputs(KTEPS) 1669.53\n",
      "\n",
      "Test accuracy 80.45%\n"
     ]
    }
   ],
   "source": [
    "graphCovNN(args1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
