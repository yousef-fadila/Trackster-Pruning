{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_store = pd.read_hdf(\"singlepi_e100GeV_pu200Nov7.h5\")\n",
    "prev_store = pd.read_hdf(\"singlepi_e100GeV_pu200_oct27.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the old data of october 27 to use it as test data. \n",
    "prev_store['purity']=prev_store['purity'].apply(lambda x: 0 if x <=1 else 1 )\n",
    "XOct27Test = prev_store.drop(['purity','event','trackster','trckType'],1,inplace=False)\n",
    "YOct27Test = prev_store[['purity']].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_store.drop(['trckType'],1,inplace=False)\n",
    "df['purity']=df['purity'].apply(lambda x: 0 if x <=1 else 1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29185005, 0.24363646, 0.17289322, 0.13004571, 0.07764744,\n",
       "       0.03569065, 0.02695563, 0.00822576, 0.0073457 , 0.00472424,\n",
       "       0.00098514])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF=df.sample(frac=0.9,random_state=200) #random state is a seed value\n",
    "testDF=df.drop(trainDF.index)\n",
    "\n",
    "x0Train = trainDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "x0Test = testDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "\n",
    "sc = StandardScaler()\n",
    "x0Train = sc.fit_transform(x0Train)\n",
    "x0Test = sc.transform(x0Test)\n",
    "\n",
    "y0Train = trainDF[['purity']].iloc[:,0]\n",
    "y0Test =  testDF[['purity']].iloc[:,0]\n",
    "\n",
    "\n",
    "pca = PCA(n_components= None)\n",
    "pca.fit_transform(x0Train)\n",
    "pca.transform(x0Test)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47804988, 0.20712209, 0.18171881, 0.06416708, 0.02239336,\n",
       "       0.01944824, 0.01485702, 0.0069028 , 0.00262831, 0.00146596,\n",
       "       0.00124645])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF=df.sample(frac=0.9,random_state=200) #random state is a seed value\n",
    "testDF=df.drop(trainDF.index)\n",
    "\n",
    "x0Train = trainDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "x0Test = testDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "x0Train = sc.fit_transform(x0Train)\n",
    "x0Test = sc.transform(x0Test)\n",
    "\n",
    "y0Train = trainDF[['purity']].iloc[:,0]\n",
    "y0Test =  testDF[['purity']].iloc[:,0]\n",
    "\n",
    "\n",
    "pca = PCA(n_components= None)\n",
    "pca.fit_transform(x0Train)\n",
    "pca.transform(x0Test)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion_matrix\n",
      "[[1934   96]\n",
      " [ 177  381]]\n",
      "Test accuracy\n",
      "0.8945131375579598\n",
      "Test Percision\n",
      "0.7987421383647799\n",
      "Test recall\n",
      "0.6827956989247311\n",
      "Test F1 score\n",
      "0.7362318840579711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20184731\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf0 = LogisticRegression(random_state=1234).fit(x0Train, y0Train)\n",
    "y0TestPred = clf0.predict(x0Test) \n",
    "\n",
    "print(\"Testing confusion_matrix\")\n",
    "print(confusion_matrix(y0Test, y0TestPred))\n",
    "\n",
    "print(\"Test accuracy\")\n",
    "print(sklearn.metrics.accuracy_score(y0Test, y0TestPred))\n",
    "print(\"Test Percision\")\n",
    "print(sklearn.metrics.precision_score(y0Test, y0TestPred))\n",
    "print(\"Test recall\")\n",
    "print(sklearn.metrics.recall_score(y0Test, y0TestPred))\n",
    "print(\"Test F1 score\")\n",
    "print(sklearn.metrics.f1_score(y0Test, y0TestPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1,5, 10,100]\n",
    "    gammas = [0.001, 0.01, 0.1,0.5, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'gamma': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_selection(pcaTrain, y0Train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion_matrix\n",
      "[[1943   87]\n",
      " [ 150  408]]\n",
      "Test accuracy\n",
      "0.9084234930448223\n",
      "Test Percision\n",
      "0.8242424242424242\n",
      "Test recall\n",
      "0.7311827956989247\n",
      "Test F1 score\n",
      "0.774928774928775\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components= 7) # here you can change this number to play around\n",
    "pcaTrain = pca.fit_transform(x0Train)\n",
    "pcaTest = pca.transform(x0Test)\n",
    "\n",
    "clf0 = SVC(C=5,kernel='rbf', gamma=1).fit(pcaTrain, y0Train)\n",
    "y0TestPred = clf0.predict(pcaTest) \n",
    "\n",
    "print(\"Testing confusion_matrix\")\n",
    "print(confusion_matrix(y0Test, y0TestPred))\n",
    "\n",
    "print(\"Test accuracy\")\n",
    "print(sklearn.metrics.accuracy_score(y0Test, y0TestPred))\n",
    "print(\"Test Percision\")\n",
    "print(sklearn.metrics.precision_score(y0Test, y0TestPred))\n",
    "print(\"Test recall\")\n",
    "print(sklearn.metrics.recall_score(y0Test, y0TestPred))\n",
    "print(\"Test F1 score\")\n",
    "print(sklearn.metrics.f1_score(y0Test, y0TestPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion_matrix\n",
      "[[1942   88]\n",
      " [ 108  450]]\n",
      "Test accuracy\n",
      "0.9242658423493045\n",
      "Test Percision\n",
      "0.8364312267657993\n",
      "Test recall\n",
      "0.8064516129032258\n",
      "Test F1 score\n",
      "0.8211678832116787\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components= 7) # here you can change this number to play around\n",
    "pcaTrain = pca.fit_transform(x0Train)\n",
    "pcaTest = pca.transform(x0Test)\n",
    "\n",
    "clf0 = SVC(C=5,kernel='rbf', gamma=1).fit(pcaTrain, y0Train)\n",
    "y0TestPred = clf0.predict(pcaTest) \n",
    "\n",
    "print(\"Testing confusion_matrix\")\n",
    "print(confusion_matrix(y0Test, y0TestPred))\n",
    "\n",
    "print(\"Test accuracy\")\n",
    "print(sklearn.metrics.accuracy_score(y0Test, y0TestPred))\n",
    "print(\"Test Percision\")\n",
    "print(sklearn.metrics.precision_score(y0Test, y0TestPred))\n",
    "print(\"Test recall\")\n",
    "print(sklearn.metrics.recall_score(y0Test, y0TestPred))\n",
    "print(\"Test F1 score\")\n",
    "print(sklearn.metrics.f1_score(y0Test, y0TestPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df_groupby_avg=df.groupby(['event','trackster','layer']).mean().reset_index()\n",
    "updated_df_groupby_max=df.groupby(['event','trackster','layer']).max().reset_index()\n",
    "updated_df_groupby_min=df.groupby(['event','trackster','layer']).min().reset_index()\n",
    "updated_df_groupby_sum=df.groupby(['event','trackster','layer']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValueEventLayerTrackster(df, col, event, trackster,layer, defaultV = 0):\n",
    "    s = df.loc[(df['event'] == event) & (df['layer'] ==layer) & (df['trackster'] ==trackster) ,col ]\n",
    "    return defaultV if s.size == 0 else s.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.834830043837428"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "getValueEventLayerTrackster(updated_df_groupby_sum, 'E', 1,0,8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>trackster</th>\n",
       "      <th>purity</th>\n",
       "      <th>layer</th>\n",
       "      <th>E</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>...</th>\n",
       "      <th>trckEn</th>\n",
       "      <th>trckEta</th>\n",
       "      <th>trckPhi</th>\n",
       "      <th>RatioSiblingNHits</th>\n",
       "      <th>RatioNextNHits</th>\n",
       "      <th>RatioPrevNHits</th>\n",
       "      <th>RatioE</th>\n",
       "      <th>RatioSiblingE</th>\n",
       "      <th>RatioNextE</th>\n",
       "      <th>RatioPrevE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>1.963233</td>\n",
       "      <td>0.158004</td>\n",
       "      <td>91.118462</td>\n",
       "      <td>14.518062</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.133108</td>\n",
       "      <td>0.049770</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134952</td>\n",
       "      <td>1.931620</td>\n",
       "      <td>0.233432</td>\n",
       "      <td>92.770134</td>\n",
       "      <td>22.057596</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.232939</td>\n",
       "      <td>0.087097</td>\n",
       "      <td>0.002336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081363</td>\n",
       "      <td>1.932140</td>\n",
       "      <td>0.148012</td>\n",
       "      <td>94.262695</td>\n",
       "      <td>14.054753</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.140440</td>\n",
       "      <td>0.052511</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>1.950308</td>\n",
       "      <td>0.361422</td>\n",
       "      <td>87.475647</td>\n",
       "      <td>33.068218</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.040045</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088878</td>\n",
       "      <td>1.911650</td>\n",
       "      <td>0.356526</td>\n",
       "      <td>91.242096</td>\n",
       "      <td>33.982418</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.153412</td>\n",
       "      <td>0.057362</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event  trackster  purity  layer         E       eta       phi          x  \\\n",
       "0    1.0        0.0       0    1.0  0.077115  1.963233  0.158004  91.118462   \n",
       "1    1.0        0.0       0    1.0  0.134952  1.931620  0.233432  92.770134   \n",
       "2    1.0        0.0       0    1.0  0.081363  1.932140  0.148012  94.262695   \n",
       "3    1.0        0.0       0    1.0  0.023200  1.950308  0.361422  87.475647   \n",
       "4    1.0        0.0       0    1.0  0.088878  1.911650  0.356526  91.242096   \n",
       "\n",
       "           y           z  ...     trckEn   trckEta   trckPhi  \\\n",
       "0  14.518062  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "1  22.057596  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "2  14.054753  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "3  33.068218  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "4  33.982418  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "\n",
       "   RatioSiblingNHits  RatioNextNHits  RatioPrevNHits    RatioE  RatioSiblingE  \\\n",
       "0           0.178571        0.128205             5.0  0.001335       0.133108   \n",
       "1           0.250000        0.179487             7.0  0.002336       0.232939   \n",
       "2           0.071429        0.051282             2.0  0.001409       0.140440   \n",
       "3           0.071429        0.051282             2.0  0.000402       0.040045   \n",
       "4           0.071429        0.051282             2.0  0.001539       0.153412   \n",
       "\n",
       "   RatioNextE  RatioPrevE  \n",
       "0    0.049770    0.001335  \n",
       "1    0.087097    0.002336  \n",
       "2    0.052511    0.001409  \n",
       "3    0.014973    0.000402  \n",
       "4    0.057362    0.001539  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df = df.copy()\n",
    "\n",
    "updated_df['RatioSiblingNHits'] = updated_df.apply(lambda row: row['nHits'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'nHits', row['event'], row['trackster'], row['layer'] ), axis=1)\n",
    "updated_df['RatioNextNHits'] = updated_df.apply(lambda row: row['nHits'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'nHits', row['event'], row['trackster'], row['layer'] + 1, 1 ), axis=1)\n",
    "updated_df['RatioPrevNHits'] = updated_df.apply(lambda row: row['nHits'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'nHits', row['event'], row['trackster'], row['layer'] - 1, 1 ), axis=1)\n",
    "\n",
    "updated_df['RatioE'] = updated_df.apply(lambda row: row['E'] / row['trckEn'], axis=1)\n",
    "updated_df['RatioSiblingE'] = updated_df.apply(lambda row: row['E'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer']), axis=1)\n",
    "\n",
    "updated_df['RatioNextE'] = updated_df.apply(lambda row: row['E'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer'] + 1,row['trckEn']), axis=1)\n",
    "\n",
    "updated_df['RatioPrevE'] =  updated_df.apply(lambda row: row['E'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer'] - 1, row['trckEn']), axis=1)\n",
    "\n",
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26021411, 0.17140689, 0.11282183, 0.10460166, 0.06130509,\n",
       "       0.05619657, 0.05155926, 0.04293485, 0.03941528, 0.02769174,\n",
       "       0.02224504, 0.01805746, 0.01568584, 0.00490463, 0.004483  ,\n",
       "       0.0030133 , 0.00286292, 0.00060053])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainExtendedDF=updated_df.sample(frac=0.9,random_state=200) #random state is a seed value\n",
    "testExtendedDF=updated_df.drop(trainDF.index)\n",
    "\n",
    "xExtendedTrain = trainExtendedDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "xExtendedTest = testExtendedDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "\n",
    "sc = StandardScaler()\n",
    "xExtendedTrain = sc.fit_transform(xExtendedTrain)\n",
    "xExtendedTest = sc.transform(xExtendedTest)\n",
    "\n",
    "yTrain = trainDF[['purity']].iloc[:,0]\n",
    "yTest =  testDF[['purity']].iloc[:,0]\n",
    "\n",
    "pca = PCA(n_components= None)\n",
    "pca.fit_transform(xExtendedTrain)\n",
    "pca.transform(xExtendedTest)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 7) # here you can change this number to play around\n",
    "pcaExtendedTrain = pca.fit_transform(xExtendedTrain)\n",
    "pcaExtendedTest = pca.transform(xExtendedTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.5}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_selection(pcaExtendedTrain, yTrain, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion_matrix\n",
      "[[1924  106]\n",
      " [ 118  440]]\n",
      "Test accuracy\n",
      "0.9134466769706336\n",
      "Test Percision\n",
      "0.8058608058608059\n",
      "Test recall\n",
      "0.7885304659498208\n",
      "Test F1 score\n",
      "0.7971014492753623\n"
     ]
    }
   ],
   "source": [
    "clf0 = SVC(C=10,kernel='rbf', gamma=0.5).fit(pcaExtendedTrain, yTrain)\n",
    "y0TestPred = clf0.predict(pcaExtendedTest) \n",
    "\n",
    "print(\"Testing confusion_matrix\")\n",
    "print(confusion_matrix(yTest, y0TestPred))\n",
    "\n",
    "print(\"Test accuracy\")\n",
    "print(sklearn.metrics.accuracy_score(yTest, y0TestPred))\n",
    "print(\"Test Percision\")\n",
    "print(sklearn.metrics.precision_score(yTest, y0TestPred))\n",
    "print(\"Test recall\")\n",
    "print(sklearn.metrics.recall_score(yTest, y0TestPred))\n",
    "print(\"Test F1 score\")\n",
    "print(sklearn.metrics.f1_score(yTest, y0TestPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Scaling - No Pca\n",
    "trainDF=df.sample(frac=0.9,random_state=200) #random state is a seed value\n",
    "testDF=df.drop(trainDF.index)\n",
    "\n",
    "xNoScalingTrain = trainDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "yNoScalingTrain = trainDF[['purity']].iloc[:,0]\n",
    "\n",
    "xNoScalingTest = testDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "yNoScalingTest =  testDF[['purity']].iloc[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion_matrix\n",
      "[[1947   83]\n",
      " [ 111  447]]\n",
      "Test accuracy\n",
      "0.9250386398763524\n",
      "Test Percision\n",
      "0.8433962264150944\n",
      "Test recall\n",
      "0.8010752688172043\n",
      "Test F1 score\n",
      "0.8216911764705883\n"
     ]
    }
   ],
   "source": [
    "clf0 = SVC(C=1,kernel='rbf', gamma=0.01).fit(xNoScalingTrain, yNoScalingTrain)\n",
    "y0TestPred = clf0.predict(xNoScalingTest) \n",
    "yTest = yNoScalingTest\n",
    "\n",
    "print(\"Testing confusion_matrix\")\n",
    "print(confusion_matrix(yTest, y0TestPred))\n",
    "\n",
    "print(\"Test accuracy\")\n",
    "print(sklearn.metrics.accuracy_score(yTest, y0TestPred))\n",
    "print(\"Test Percision\")\n",
    "print(sklearn.metrics.precision_score(yTest, y0TestPred))\n",
    "print(\"Test recall\")\n",
    "print(sklearn.metrics.recall_score(yTest, y0TestPred))\n",
    "print(\"Test F1 score\")\n",
    "print(sklearn.metrics.f1_score(yTest, y0TestPred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
