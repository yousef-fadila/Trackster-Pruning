{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from vecstack import stacking\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_store = pd.read_hdf(\"singlepi_e100GeV_pu200Nov7.h5\")\n",
    "prev_store = pd.read_hdf(\"singlepi_e100GeV_pu200_oct27.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the old data of october 27 to use it as test data. \n",
    "prev_store['purity']=prev_store['purity'].apply(lambda x: 0 if x <=1 else 1 )\n",
    "XOct27Test = prev_store.drop(['purity','event','trackster','trckType'],1,inplace=False)\n",
    "YOct27Test = prev_store[['purity']].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_store.drop(['trckType'],1,inplace=False)\n",
    "df['purity']=df['purity'].apply(lambda x: 0 if x <=1 else 1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['purity','event','trackster'],1,inplace=False)\n",
    "y = df[['purity']].iloc[:,0]\n",
    "\n",
    "sc = StandardScaler()\n",
    "SC_X = sc.fit_transform(X)\n",
    "trainDF=df.sample(frac=0.9,random_state=200) #random state is a seed value\n",
    "testDF=df.drop(trainDF.index)\n",
    "\n",
    "xTrain = trainDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "xTest = testDF.drop(['purity','event','trackster'],1,inplace=False)\n",
    "\n",
    "SC_xTrain = sc.fit_transform(xTrain)\n",
    "SC_xTest = sc.transform(xTest)\n",
    "\n",
    "yTrain = trainDF[['purity']].iloc[:,0]\n",
    "yTest =  testDF[['purity']].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion_matrix\n",
      "[[1958   72]\n",
      " [  87  471]]\n",
      "Test accuracy\n",
      "0.9385625965996909\n",
      "Test Percision\n",
      "0.8674033149171271\n",
      "Test recall\n",
      "0.8440860215053764\n",
      "Test F1 score\n",
      "0.8555858310626704\n"
     ]
    }
   ],
   "source": [
    "clf0 = XGBClassifier(max_depth=50,random_state=1234).fit(xTrain, yTrain)\n",
    "yTestPred = clf0.predict(xTest) \n",
    "\n",
    "print(\"Testing confusion_matrix\")\n",
    "print(confusion_matrix(yTest, yTestPred))\n",
    "\n",
    "print(\"Test accuracy\")\n",
    "print(sklearn.metrics.accuracy_score(yTest, yTestPred))\n",
    "print(\"Test Percision\")\n",
    "print(sklearn.metrics.precision_score(yTest, yTestPred))\n",
    "print(\"Test recall\")\n",
    "print(sklearn.metrics.recall_score(yTest, yTestPred))\n",
    "print(\"Test F1 score\")\n",
    "print(sklearn.metrics.f1_score(yTest, yTestPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_MLP = MLPClassifier(alpha=0.05, hidden_layer_sizes=(50, 50, 50), random_state=1234)\n",
    "clf_RF = RandomForestClassifier(max_depth=40,n_estimators=100,random_state=1234)\n",
    "clf_SVM = SVC(C=10,kernel='rbf', gamma=0.5, random_state=1234)\n",
    "clf_XGB= XGBClassifier(max_depth=50,random_state=1234)\n",
    "\n",
    "models = [clf_MLP, clf_RF, clf_SVM, clf_XGB]\n",
    "names = [\"MLP\", \"RF\", \"SVM\", \"XGB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20184731\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy [0.88723634 0.9210384  0.90643591 0.89291509 0.8934271  0.89880952\n",
      " 0.91044372]\n",
      "test_f1 [0.69315673 0.82742317 0.76137931 0.7083947  0.74808184 0.77496992\n",
      " 0.7654146 ]\n",
      "train_accuracy [0.92476221 0.91299644 0.91380787 0.91732408 0.91534439 0.91449177\n",
      " 0.92215461]\n",
      "RF\n",
      "test_accuracy [0.88858843 0.92347215 0.90183883 0.75581395 0.74249391 0.91991342\n",
      " 0.91964286]\n",
      "test_f1 [0.70359712 0.82733374 0.76864245 0.52796654 0.57613535 0.82038835\n",
      " 0.79754601]\n",
      "train_accuracy [1. 1. 1. 1. 1. 1. 1.]\n",
      "SVM\n",
      "test_accuracy [0.78366685 0.78150352 0.78312601 0.7828556  0.78360833 0.78327922\n",
      " 0.7827381 ]\n",
      "test_f1 [0.00497512 0.00492611 0.00742574 0.         0.00990099 0.00249066\n",
      " 0.        ]\n",
      "train_accuracy [1.         1.         0.99995492 0.99995492 0.99995492 0.99995492\n",
      " 0.99995492]\n",
      "XGB\n",
      "test_accuracy [0.88236885 0.9161709  0.90156842 0.83180097 0.76088721 0.92207792\n",
      " 0.91558442]\n",
      "test_f1 [0.68637347 0.81097561 0.7699115  0.6097867  0.59634703 0.82566586\n",
      " 0.78688525]\n",
      "train_accuracy [0.9997746  0.99986476 0.99981968 0.99981968 0.99990984 0.9998197\n",
      " 0.99990985]\n"
     ]
    }
   ],
   "source": [
    "scoring = {'accuracy': 'accuracy','f1': 'f1'}\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    print (name)\n",
    "    cv_results=cross_validate(model, X, y, scoring=scoring, cv=7, return_train_score=True)\n",
    "    print(\"test_accuracy\", cv_results['test_accuracy'])\n",
    "    print(\"test_f1\", cv_results['test_f1'])\n",
    "    print(\"train_accuracy\", cv_results['train_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coress validation with feature scaling\n",
      "MLP\n",
      "test_accuracy [0.89426717 0.90183883 0.89318551 0.85667929 0.86962402 0.85497835\n",
      " 0.89204545]\n",
      "test_f1 [0.72978576 0.79005205 0.7545059  0.67243511 0.72551253 0.71428571\n",
      " 0.73698088]\n",
      "train_accuracy [0.95451472 0.95041248 0.95050264 0.95126899 0.95384061 0.9481181\n",
      " 0.95199459]\n",
      "RF\n",
      "test_accuracy [0.88750676 0.92293131 0.90156842 0.75689562 0.74087098 0.92072511\n",
      " 0.91801948]\n",
      "test_f1 [0.70200573 0.82632541 0.76726343 0.5305483  0.57232143 0.82210079\n",
      " 0.79345603]\n",
      "train_accuracy [1. 1. 1. 1. 1. 1. 1.]\n",
      "SVM\n",
      "test_accuracy [0.87750135 0.88290968 0.8815576  0.79096809 0.77901001 0.75784632\n",
      " 0.88284632]\n",
      "test_f1 [0.67480258 0.7411835  0.71335079 0.55954416 0.59373446 0.59225513\n",
      " 0.71791531]\n",
      "train_accuracy [0.95785061 0.95618266 0.95663346 0.95776045 0.95879913 0.95402299\n",
      " 0.95348208]\n",
      "XGB\n",
      "test_accuracy [0.88345051 0.91725257 0.90237966 0.83396431 0.75872329 0.9237013\n",
      " 0.91558442]\n",
      "test_f1 [0.69148175 0.81341463 0.7716635  0.61625    0.59491371 0.83012048\n",
      " 0.78804348]\n",
      "train_accuracy [0.99972952 0.99986476 0.9997746  0.9997746  0.99990984 0.99977462\n",
      " 0.99986477]\n"
     ]
    }
   ],
   "source": [
    "print('coress validation with feature scaling CV: 7')\n",
    "for model, name in zip(models, names):\n",
    "    print (name)\n",
    "    cv_results=cross_validate(model, SC_X, y, scoring=scoring, cv=7, return_train_score=True)\n",
    "    print(\"test_accuracy\", cv_results['test_accuracy'])\n",
    "    print(\"test_f1\", cv_results['test_f1'])\n",
    "    print(\"train_accuracy\", cv_results['train_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coress validation with feature scaling wiht PCA 6 - CV 10\n",
      "MLP\n",
      "test_accuracy [0.88209843 0.90481341 0.87290427 0.88804759 0.87909115 0.90746753\n",
      " 0.88988095]\n",
      "test_f1 [0.70855615 0.78871549 0.68708389 0.68965517 0.72010019 0.78409091\n",
      " 0.70226774]\n",
      "train_accuracy [0.91204977 0.91033674 0.9152955  0.91272596 0.91430761 0.91129141\n",
      " 0.90872211]\n",
      "RF\n",
      "test_accuracy [0.87209302 0.88994051 0.86749594 0.87479719 0.86205031 0.90232684\n",
      " 0.88771645]\n",
      "test_f1 [0.65848375 0.75288403 0.68264249 0.6572909  0.68902439 0.76604018\n",
      " 0.7112039 ]\n",
      "train_accuracy [1.         1.         1.         1.         0.99995492 1.\n",
      " 1.        ]\n",
      "SVM\n",
      "test_accuracy [0.87290427 0.90075717 0.87804218 0.88750676 0.87882067 0.90313853\n",
      " 0.88176407]\n",
      "test_f1 [0.65081724 0.77133956 0.7027027  0.68908819 0.71134021 0.76291391\n",
      " 0.70292318]\n",
      "train_accuracy [0.91425867 0.91074246 0.91389803 0.91376279 0.91277497 0.90944332\n",
      " 0.9100293 ]\n",
      "XGB\n",
      "test_accuracy [0.87479719 0.88534343 0.85992428 0.87155219 0.85312415 0.89799784\n",
      " 0.875     ]\n",
      "test_f1 [0.66999287 0.7454982  0.66709512 0.65753425 0.6730885  0.75375572\n",
      " 0.68049793]\n",
      "train_accuracy [0.99963936 0.99950412 0.99963936 0.99936889 0.99963938 0.99945909\n",
      " 0.99950417]\n"
     ]
    }
   ],
   "source": [
    "print('coress validation with feature scaling wiht PCA 6 - CV 10')\n",
    "\n",
    "pca = PCA(n_components= 4)\n",
    "SC_X_pca = pca.fit_transform(SC_X)\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    print (name)\n",
    "    cv_results=cross_validate(model, SC_X_pca, y, scoring=scoring, cv=7, return_train_score=True)\n",
    "    print(\"test_accuracy\", cv_results['test_accuracy'])\n",
    "    print(\"test_f1\", cv_results['test_f1'])\n",
    "    print(\"train_accuracy\", cv_results['train_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [4]\n",
      "\n",
      "model  0:     [MLPClassifier]\n",
      "    fold  0:  [0.93900240]\n",
      "    fold  1:  [0.93629808]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20184731\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.92938702]\n",
      "    fold  3:  [0.93569712]\n",
      "    fold  4:  [0.93567779]\n",
      "    fold  5:  [0.92726180]\n",
      "    fold  6:  [0.92816351]\n",
      "    ----\n",
      "    MEAN:     [0.93306967] + [0.00432087]\n",
      "    FULL:     [0.93307002]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.93810096]\n",
      "    fold  1:  [0.94411058]\n",
      "    fold  2:  [0.93479567]\n",
      "    fold  3:  [0.94381010]\n",
      "    fold  4:  [0.93988578]\n",
      "    fold  5:  [0.93748121]\n",
      "    fold  6:  [0.93748121]\n",
      "    ----\n",
      "    MEAN:     [0.93938079] + [0.00320987]\n",
      "    FULL:     [0.93938093]\n",
      "\n",
      "model  2:     [SVC]\n",
      "    fold  0:  [0.93840144]\n",
      "    fold  1:  [0.93629808]\n",
      "    fold  2:  [0.92728365]\n",
      "    fold  3:  [0.93840144]\n",
      "    fold  4:  [0.93116922]\n",
      "    fold  5:  [0.92876465]\n",
      "    fold  6:  [0.93026751]\n",
      "    ----\n",
      "    MEAN:     [0.93294086] + [0.00432000]\n",
      "    FULL:     [0.93294123]\n",
      "\n",
      "model  3:     [XGBClassifier]\n",
      "    fold  0:  [0.94260817]\n",
      "    fold  1:  [0.94230769]\n",
      "    fold  2:  [0.94050481]\n",
      "    fold  3:  [0.94801683]\n",
      "    fold  4:  [0.94409378]\n",
      "    fold  5:  [0.94168921]\n",
      "    fold  6:  [0.93958521]\n",
      "    ----\n",
      "    MEAN:     [0.94268653] + [0.00256110]\n",
      "    FULL:     [0.94268664]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train, S_test = stacking(models,                     # list of models\n",
    "                           SC_xTrain, yTrain, SC_xTest,   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=False,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           metric=accuracy_score,      # metric: callable\n",
    "                           n_folds=7,                  # number of folds\n",
    "                           random_state=1234,             # ensure reproducibility\n",
    "                           verbose=2)                  # print all info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 4 clfs match 21649\n",
      "no match in the 4 clfs  1644\n",
      "percentage  0.0759388424407594\n"
     ]
    }
   ],
   "source": [
    "a=np.sum(S_train, axis=1)\n",
    "print(\"all 4 clfs match\", np.count_nonzero( np.logical_or(a==0,a==4)))\n",
    "print(\"no match in the 4 clfs \", np.count_nonzero( np.logical_and(a!=0,a!=4)))\n",
    "print(\"percentage \",np.count_nonzero( np.logical_and(a!=0,a!=4))/np.count_nonzero( np.logical_or(a==0,a==4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_train[1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: [0.93701700]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize 2nd level model\n",
    "metaModel_XGB = XGBClassifier(max_depth=10,random_state=1234, n_estimators=100)\n",
    "\n",
    "# Fit 2nd level model\n",
    "clf_meta_xgb = metaModel_XGB.fit(S_train, yTrain)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf_meta_xgb.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % accuracy_score(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [4]\n",
      "\n",
      "model  0:     [MLPClassifier]\n",
      "    fold  0:  [0.90985577]\n",
      "    fold  1:  [0.90895433]\n",
      "    fold  2:  [0.90685096]\n",
      "    fold  3:  [0.91195913]\n",
      "    fold  4:  [0.90411782]\n",
      "    fold  5:  [0.90652239]\n",
      "    fold  6:  [0.90141268]\n",
      "    ----\n",
      "    MEAN:     [0.90709616] + [0.00330105]\n",
      "    FULL:     [0.90709655]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.90625000]\n",
      "    fold  1:  [0.91256010]\n",
      "    fold  2:  [0.90685096]\n",
      "    fold  3:  [0.90985577]\n",
      "    fold  4:  [0.89930869]\n",
      "    fold  5:  [0.90501954]\n",
      "    fold  6:  [0.90081154]\n",
      "    ----\n",
      "    MEAN:     [0.90580808] + [0.00432742]\n",
      "    FULL:     [0.90580861]\n",
      "\n",
      "model  2:     [SVC]\n",
      "    fold  0:  [0.90655048]\n",
      "    fold  1:  [0.91346154]\n",
      "    fold  2:  [0.90294471]\n",
      "    fold  3:  [0.91015625]\n",
      "    fold  4:  [0.90021040]\n",
      "    fold  5:  [0.90261497]\n",
      "    fold  6:  [0.90351668]\n",
      "    ----\n",
      "    MEAN:     [0.90563643] + [0.00435572]\n",
      "    FULL:     [0.90563689]\n",
      "\n",
      "model  3:     [XGBClassifier]\n",
      "    fold  0:  [0.90594952]\n",
      "    fold  1:  [0.91496394]\n",
      "    fold  2:  [0.90895433]\n",
      "    fold  3:  [0.90955529]\n",
      "    fold  4:  [0.90021040]\n",
      "    fold  5:  [0.89960926]\n",
      "    fold  6:  [0.89570183]\n",
      "    ----\n",
      "    MEAN:     [0.90499208] + [0.00626812]\n",
      "    FULL:     [0.90499292]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components= 4)\n",
    "SC_xTrain_pca = pca.fit_transform(SC_xTrain)\n",
    "SC_xTest_pca = pca.fit_transform(SC_xTest)\n",
    "\n",
    "S_train_pca, S_test_pca = stacking(models,                     # list of models\n",
    "                           SC_xTrain_pca, yTrain, SC_xTest_pca,   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=False,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           metric=accuracy_score,      # metric: callable\n",
    "                           n_folds=7,                  # number of folds\n",
    "                           random_state=1234,             # ensure reproducibility\n",
    "                           verbose=2)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 4 clfs match 21841\n",
      "no match in the 4 clfs  1452\n",
      "percentage  0.06648047250583765\n"
     ]
    }
   ],
   "source": [
    "a=np.sum(S_train_pca, axis=1)\n",
    "print(\"all 4 clfs match\", np.count_nonzero( np.logical_or(a==0,a==4)))\n",
    "print(\"no match in the 4 clfs \", np.count_nonzero( np.logical_and(a!=0,a!=4)))\n",
    "print(\"percentage \",np.count_nonzero( np.logical_and(a!=0,a!=4))/np.count_nonzero( np.logical_or(a==0,a==4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction accuracy score: [0.89451314]\n",
      "Final prediction F1 score: [0.75249320]\n"
     ]
    }
   ],
   "source": [
    "# Initialize 2nd level model\n",
    "metaModel_XGB = XGBClassifier(max_depth=25,random_state=1234, n_estimators=100)\n",
    "\n",
    "# Fit 2nd level model\n",
    "clf_meta_xgb = metaModel_XGB.fit(S_train_pca, yTrain)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf_meta_xgb.predict(S_test_pca)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction accuracy score: [%.8f]' % sklearn.metrics.accuracy_score(yTest, y_pred))\n",
    "print('Final prediction F1 score: [%.8f]' % sklearn.metrics.f1_score(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking with extended Featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df_groupby_avg=df.groupby(['event','trackster','layer']).mean().reset_index()\n",
    "updated_df_groupby_max=df.groupby(['event','trackster','layer']).max().reset_index()\n",
    "updated_df_groupby_min=df.groupby(['event','trackster','layer']).min().reset_index()\n",
    "updated_df_groupby_sum=df.groupby(['event','trackster','layer']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValueEventLayerTrackster(df, col, event, trackster,layer, defaultV = 0):\n",
    "    s = df.loc[(df['event'] == event) & (df['layer'] ==layer) & (df['trackster'] ==trackster) ,col ]\n",
    "    return defaultV if s.size == 0 else s.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>trackster</th>\n",
       "      <th>purity</th>\n",
       "      <th>layer</th>\n",
       "      <th>E</th>\n",
       "      <th>eta</th>\n",
       "      <th>phi</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>...</th>\n",
       "      <th>trckEn</th>\n",
       "      <th>trckEta</th>\n",
       "      <th>trckPhi</th>\n",
       "      <th>RatioSiblingNHits</th>\n",
       "      <th>RatioNextNHits</th>\n",
       "      <th>RatioPrevNHits</th>\n",
       "      <th>RatioE</th>\n",
       "      <th>RatioSiblingE</th>\n",
       "      <th>RatioNextE</th>\n",
       "      <th>RatioPrevE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>1.963233</td>\n",
       "      <td>0.158004</td>\n",
       "      <td>91.118462</td>\n",
       "      <td>14.518062</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.133108</td>\n",
       "      <td>0.049770</td>\n",
       "      <td>0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.134952</td>\n",
       "      <td>1.931620</td>\n",
       "      <td>0.233432</td>\n",
       "      <td>92.770134</td>\n",
       "      <td>22.057596</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.232939</td>\n",
       "      <td>0.087097</td>\n",
       "      <td>0.002336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.081363</td>\n",
       "      <td>1.932140</td>\n",
       "      <td>0.148012</td>\n",
       "      <td>94.262695</td>\n",
       "      <td>14.054753</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.140440</td>\n",
       "      <td>0.052511</td>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>1.950308</td>\n",
       "      <td>0.361422</td>\n",
       "      <td>87.475647</td>\n",
       "      <td>33.068218</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.040045</td>\n",
       "      <td>0.014973</td>\n",
       "      <td>0.000402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088878</td>\n",
       "      <td>1.911650</td>\n",
       "      <td>0.356526</td>\n",
       "      <td>91.242096</td>\n",
       "      <td>33.982418</td>\n",
       "      <td>322.102753</td>\n",
       "      <td>...</td>\n",
       "      <td>57.759506</td>\n",
       "      <td>1.897144</td>\n",
       "      <td>0.196742</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.153412</td>\n",
       "      <td>0.057362</td>\n",
       "      <td>0.001539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event  trackster  purity  layer         E       eta       phi          x  \\\n",
       "0    1.0        0.0       0    1.0  0.077115  1.963233  0.158004  91.118462   \n",
       "1    1.0        0.0       0    1.0  0.134952  1.931620  0.233432  92.770134   \n",
       "2    1.0        0.0       0    1.0  0.081363  1.932140  0.148012  94.262695   \n",
       "3    1.0        0.0       0    1.0  0.023200  1.950308  0.361422  87.475647   \n",
       "4    1.0        0.0       0    1.0  0.088878  1.911650  0.356526  91.242096   \n",
       "\n",
       "           y           z  ...     trckEn   trckEta   trckPhi  \\\n",
       "0  14.518062  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "1  22.057596  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "2  14.054753  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "3  33.068218  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "4  33.982418  322.102753  ...  57.759506  1.897144  0.196742   \n",
       "\n",
       "   RatioSiblingNHits  RatioNextNHits  RatioPrevNHits    RatioE  RatioSiblingE  \\\n",
       "0           0.178571        0.128205             5.0  0.001335       0.133108   \n",
       "1           0.250000        0.179487             7.0  0.002336       0.232939   \n",
       "2           0.071429        0.051282             2.0  0.001409       0.140440   \n",
       "3           0.071429        0.051282             2.0  0.000402       0.040045   \n",
       "4           0.071429        0.051282             2.0  0.001539       0.153412   \n",
       "\n",
       "   RatioNextE  RatioPrevE  \n",
       "0    0.049770    0.001335  \n",
       "1    0.087097    0.002336  \n",
       "2    0.052511    0.001409  \n",
       "3    0.014973    0.000402  \n",
       "4    0.057362    0.001539  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df = df.copy()\n",
    "#updated_df['prevAvgEta'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'eta', row['event'], row['trackster'], row['layer'] - 1, row['trckEta']), axis=1)\n",
    "#updated_df['prevAvgPhi'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'phi', row['event'], row['trackster'], row['layer'] - 1,row['trckPhi']), axis=1)\n",
    "#updated_df['prevAvgE'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'E', row['event'], row['trackster'], row['layer'] - 1), axis=1)\n",
    "#updated_df['PrevSumE'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer'] - 1), axis=1)\n",
    "\n",
    "#updated_df['NextAvgEta'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'eta', row['event'], row['trackster'], row['layer'] + 1,row['trckEta']), axis=1)\n",
    "#updated_df['NextAvgPhi'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'phi', row['event'], row['trackster'], row['layer'] + 1,row['trckPhi']), axis=1)\n",
    "#updated_df['NextAvgE'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'E', row['event'], row['trackster'], row['layer'] + 1), axis=1)\n",
    "#updated_df['NextSumE'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer'] + 1), axis=1)\n",
    "\n",
    "#updated_df['SiblingAvgEta'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'eta', row['event'], row['trackster'], row['layer'],row['trckEta'] ), axis=1)\n",
    "#updated_df['SiblingAvgPhi'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'phi', row['event'], row['trackster'], row['layer'],row['trckPhi'] ), axis=1)\n",
    "#updated_df['SiblingAvgE'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_avg, 'E', row['event'], row['trackster'], row['layer'] ), axis=1)\n",
    "#updated_df['SiblingSumE'] = updated_df.apply(lambda row: getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer'] ), axis=1)\n",
    "\n",
    "updated_df['RatioSiblingNHits'] = updated_df.apply(lambda row: row['nHits'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'nHits', row['event'], row['trackster'], row['layer'] ), axis=1)\n",
    "updated_df['RatioNextNHits'] = updated_df.apply(lambda row: row['nHits'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'nHits', row['event'], row['trackster'], row['layer'] + 1, 1 ), axis=1)\n",
    "updated_df['RatioPrevNHits'] = updated_df.apply(lambda row: row['nHits'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'nHits', row['event'], row['trackster'], row['layer'] - 1, 1 ), axis=1)\n",
    "\n",
    "updated_df['RatioE'] = updated_df.apply(lambda row: row['E'] / row['trckEn'], axis=1)\n",
    "updated_df['RatioSiblingE'] = updated_df.apply(lambda row: row['E'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer']), axis=1)\n",
    "\n",
    "\n",
    "updated_df['RatioNextE'] = updated_df.apply(lambda row: row['E'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer'] + 1,row['trckEn']), axis=1)\n",
    "\n",
    "updated_df['RatioPrevE'] =  updated_df.apply(lambda row: row['E'] / getValueEventLayerTrackster(updated_df_groupby_sum, 'E', row['event'], row['trackster'], row['layer'] - 1, row['trckEn']), axis=1)\n",
    "\n",
    "updated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extended = updated_df.drop(['purity','event','trackster'],1,inplace=False)\n",
    "y_extended = updated_df[['purity']].iloc[:,0]\n",
    "\n",
    "SC_X_extended = sc.fit_transform(X_extended)\n",
    "\n",
    "trainDF_extended=df.sample(frac=0.9,random_state=200) #random state is a seed value\n",
    "testDF_extended=df.drop(trainDF.index)\n",
    "\n",
    "xTrain_extended = trainDF_extended.drop(['purity','event','trackster'],1,inplace=False)\n",
    "xTest_extended = testDF_extended.drop(['purity','event','trackster'],1,inplace=False)\n",
    "\n",
    "SC_xTrain_extended = sc.fit_transform(xTrain_extended)\n",
    "SC_xTest_extended = sc.transform(xTest_extended)\n",
    "\n",
    "yTrain_extended = trainDF[['purity']].iloc[:,0]\n",
    "yTest_extended =  testDF[['purity']].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coress validation with extended features and scaling\n",
      "MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20184731\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\20184731\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy [0.88777718 0.90697674 0.88182802 0.86235803 0.82769813 0.85633117\n",
      " 0.88582251]\n",
      "test_f1 [0.72534745 0.78712871 0.7270456  0.65491525 0.65548945 0.71919619\n",
      " 0.71016484]\n",
      "train_accuracy [0.96181761 0.95992427 0.96154713 0.96533381 0.95843851 0.96164075\n",
      " 0.95920667]\n",
      "RF\n",
      "test_accuracy [0.89102217 0.92915089 0.90886966 0.76203353 0.7454693  0.92640693\n",
      " 0.91747835]\n",
      "test_f1 [0.7115247  0.8398533  0.78383579 0.54545455 0.57090743 0.83168317\n",
      " 0.79293958]\n",
      "train_accuracy [1.         1.         1.         0.99995492 1.         1.\n",
      " 1.        ]\n",
      "SVM\n",
      "test_accuracy [0.8783126  0.88372093 0.87182261 0.74067063 0.77819854 0.76569264\n",
      " 0.85281385]\n",
      "test_f1 [0.68265162 0.75258918 0.70485679 0.52312282 0.6        0.60600546\n",
      " 0.67268351]\n",
      "train_accuracy [0.96975161 0.96695668 0.96776811 0.97011225 0.97015867 0.96664413\n",
      " 0.96673428]\n",
      "XGB\n",
      "test_accuracy [0.89102217 0.92184965 0.90589508 0.84910763 0.77116581 0.92694805\n",
      " 0.91910173]\n",
      "test_f1 [0.70733479 0.82495457 0.77918782 0.64861461 0.60577819 0.83374384\n",
      " 0.79892401]\n",
      "train_accuracy [0.99986476 0.99990984 0.99986476 0.99986476 0.99990984 0.99990985\n",
      " 0.99990985]\n"
     ]
    }
   ],
   "source": [
    "print('coress validation with extended features and scaling')\n",
    "for model, name in zip(models, names):\n",
    "    print (name)\n",
    "    cv_results=cross_validate(model, SC_X_extended, y_extended, scoring=scoring, cv=7, return_train_score=True)\n",
    "    print(\"test_accuracy\", cv_results['test_accuracy'])\n",
    "    print(\"test_f1\", cv_results['test_f1'])\n",
    "    print(\"train_accuracy\", cv_results['train_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [4]\n",
      "\n",
      "model  0:     [MLPClassifier]\n",
      "    fold  0:  [0.93900240]\n",
      "    fold  1:  [0.93629808]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20184731\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.92938702]\n",
      "    fold  3:  [0.93569712]\n",
      "    fold  4:  [0.93567779]\n",
      "    fold  5:  [0.92726180]\n",
      "    fold  6:  [0.92816351]\n",
      "    ----\n",
      "    MEAN:     [0.93306967] + [0.00432087]\n",
      "    FULL:     [0.93307002]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.93810096]\n",
      "    fold  1:  [0.94411058]\n",
      "    fold  2:  [0.93479567]\n",
      "    fold  3:  [0.94381010]\n",
      "    fold  4:  [0.93988578]\n",
      "    fold  5:  [0.93748121]\n",
      "    fold  6:  [0.93748121]\n",
      "    ----\n",
      "    MEAN:     [0.93938079] + [0.00320987]\n",
      "    FULL:     [0.93938093]\n",
      "\n",
      "model  2:     [SVC]\n",
      "    fold  0:  [0.93840144]\n",
      "    fold  1:  [0.93629808]\n",
      "    fold  2:  [0.92728365]\n",
      "    fold  3:  [0.93840144]\n",
      "    fold  4:  [0.93116922]\n",
      "    fold  5:  [0.92876465]\n",
      "    fold  6:  [0.93026751]\n",
      "    ----\n",
      "    MEAN:     [0.93294086] + [0.00432000]\n",
      "    FULL:     [0.93294123]\n",
      "\n",
      "model  3:     [XGBClassifier]\n",
      "    fold  0:  [0.94260817]\n",
      "    fold  1:  [0.94230769]\n",
      "    fold  2:  [0.94050481]\n",
      "    fold  3:  [0.94801683]\n",
      "    fold  4:  [0.94409378]\n",
      "    fold  5:  [0.94168921]\n",
      "    fold  6:  [0.93958521]\n",
      "    ----\n",
      "    MEAN:     [0.94268653] + [0.00256110]\n",
      "    FULL:     [0.94268664]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train_extended, S_test_extended = stacking(models,                     # list of models\n",
    "                           SC_xTrain_extended, yTrain_extended, SC_xTest_extended,   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=False,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           metric=accuracy_score,      # metric: callable\n",
    "                           n_folds=7,                  # number of folds\n",
    "                           random_state=1234,             # ensure reproducibility\n",
    "                           verbose=2)                  # print all info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 4 clfs match 21649\n",
      "no match in the 4 clfs  1644\n",
      "percentage  0.0759388424407594\n"
     ]
    }
   ],
   "source": [
    "a=np.sum(S_train_extended, axis=1)\n",
    "print(\"all 4 clfs match\", np.count_nonzero( np.logical_or(a==0,a==4)))\n",
    "print(\"no match in the 4 clfs \", np.count_nonzero( np.logical_and(a!=0,a!=4)))\n",
    "print(\"percentage \",np.count_nonzero( np.logical_and(a!=0,a!=4))/np.count_nonzero( np.logical_or(a==0,a==4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: [0.93701700]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize 2nd level model\n",
    "metaModel_XGB = XGBClassifier(max_depth=25,random_state=1234, n_estimators=100)\n",
    "\n",
    "# Fit 2nd level model\n",
    "clf_meta_xgb = metaModel_XGB.fit(S_train_extended, yTrain_extended)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf_meta_xgb.predict(S_test_extended)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % accuracy_score(yTest_extended, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
